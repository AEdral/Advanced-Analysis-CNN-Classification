# Relazione del Progetto di Tesi

**Data**: 07/10/2024


## Cos'è SHAP?

SHAP (SHapley Additive exPlanations) è un framework che fornisce una spiegazione interpretabile per i modelli di machine learning. La sua base teorica si ispira ai valori di Shapley dalla teoria dei giochi, i quali rappresentano una distribuzione equa dei guadagni (o dei contributi) tra i partecipanti di un gioco cooperativo. Applicato ai modelli di machine learning, SHAP calcola il contributo di ciascun feature (o parte del dato di input) alla predizione fatta dal modello.

Nel contesto delle immagini, SHAP aiuta a determinare quali regioni dell'immagine influenzano maggiormente la decisione del modello, restituendo una mappa di importanza visiva (heatmap) sovrapposta all'immagine originale. Questa spiegazione è particolarmente utile per comprendere come una rete neurale convoluzionale (CNN) come la VGG16 "vede" un'immagine.

## Implementazione di SHAP su VGG16

Nella nostra implementazione, abbiamo utilizzato il modello VGG16, preaddestrato su ImageNet, e applicato SHAP per spiegare il suo comportamento su un dataset di immagini di COVID-19, normalizzando le immagini per essere compatibili con le esigenze di input del modello.


## Test con un altro modello e dataset: ResNet50 e ImageNet

Abbiamo testato SHAP con un altro modello preaddestrato, ResNet50, e un campione del dataset ImageNet (contenente 50 immagini casuali e più classi). La funzione di preprocessamento per ResNet50 è simile a quella usata per VGG16, ma con alcune differenze specifiche per la rete.

Questo test è stato fondamentale per avere un punto di partenza funzionante per applicare poi il metodo al mio modello/dataset.

-   [SHAP ResNet50 - ImageNet](shap_resnet.png)

## Test con il mio modello e dataset COVID-19

Nel caso del nostro modello VGG16 addestrato su immagini COVID-19, abbiamo applicato lo stesso approccio. Abbiamo utilizzato un dataset di immagini di raggi X per classificare le immagini come "COVID-19", "Polmonite virale", o "Normale". I valori SHAP hanno permesso di evidenziare quali aree delle immagini influenzano maggiormente la classificazione, fornendo un'interpretazione visiva di come la rete VGG16 prenda le sue decisioni. 

Da notare che il modello vgg16 pretrainato ha tre classi ("COVID-19", "Polmonite virale", o "Normale") mentre il dataset utilizzato ne ha solo due: COVID-19 e Normale. Quindi nel risultato si vede che l'output 1 ovvero quello legato a Polmonite virale risulta sempre nullo.

-   [SHAP VGG16 - COVID-19](shap_vgg16.png)

## Interpretazione dei risultati

Durante i test, SHAP ha restituito mappe di calore che mostravano le regioni di maggiore importanza per la predizione del modello. In alcuni casi, le immagini SHAP erano caratterizzate da valori bianchi o rossi, che indicano aree che hanno fortemente influenzato la predizione verso una determinata classe. Tuttavia, la visualizzazione dell'immagine preprocessata (dopo il passaggio di normalizzazione) appariva talvolta scura o con una distribuzione anomala dei colori. Ciò è dovuto al fatto che la rete VGG16 normalizza le immagini in modo diverso rispetto ai modelli tradizionali, centrando i valori intorno a zero.

-   [Normalizzazione VGG16](shap_vgg16_norm.png)




