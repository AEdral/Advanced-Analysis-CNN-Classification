# Abstract

This thesis aims to study the decision-making process of a convolutional neural network (CNN), with a focus on analyzing the distinctive patterns extracted during the classification of radiographic images (X-rays) into three classes: **COVID-19, viral pneumonia, and non-pathological images**.  

The main objectives include:  
- Analyzing the network’s decision-making process,  
- Visually exploring the relevant areas in the images for each class,  
- Examining classification errors.  

To achieve these goals, three explainability frameworks — **GradCAM, LIME, and SHAP** — were employed and compared. These tools provide:  
- A visual analysis of the areas considered relevant by the network,  
- An in-depth examination of the network’s internal workings, layer by layer,  
- A statistical method to calculate class similarity.  

The results of this work will contribute to enhancing the understanding of the model’s decisions and improving transparency in medical diagnostics.
