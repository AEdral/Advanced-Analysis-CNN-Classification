{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPA+9rwudwocXOsr2/bje0G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cufWGKNxdQi3","executionInfo":{"status":"ok","timestamp":1725986463992,"user_tz":-120,"elapsed":313,"user":{"displayName":"Francesco Pineschi","userId":"02082134800081524813"}},"outputId":"fe326c27-8e78-4061-f29f-964f115609e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing ml_utils.py\n"]}],"source":["import os\n","import re\n","import pandas as pd\n","from tensorflow.keras.callbacks import Callback\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","\n","def test(): return 'prova'\n","\n","class CSVLoggerCallback(Callback):\n","    def __init__(self, path):\n","        super(CSVLoggerCallback, self).__init__()\n","        self.path = path\n","        self.history_file = os.path.join(self.path, 'training_history.csv')\n","\n","        # Crea la directory se non esiste\n","        if not os.path.exists(self.path):\n","            os.makedirs(self.path)\n","\n","        # Controllo se il file CSV esiste già\n","        self.file_exists = os.path.exists(self.history_file)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # Estrazione dei dati di interesse alla fine dell'epoca\n","        logs = logs or {}\n","        epoch_data = {\n","            'epoch': [epoch + 1],\n","            'training_accuracy': [logs.get('accuracy')],\n","            'training_loss': [logs.get('loss')],\n","            'validation_accuracy': [logs.get('val_accuracy')],\n","            'validation_loss': [logs.get('val_loss')]\n","        }\n","\n","        # Creiamo un DataFrame per la singola epoca\n","        epoch_df = pd.DataFrame(epoch_data)\n","\n","        # Se il file esiste già, appendo i nuovi dati senza intestazione\n","        if self.file_exists:\n","            epoch_df.to_csv(self.history_file, mode='a', header=False, index=False)\n","        else:\n","            # Se il file non esiste, lo creo con l'intestazione\n","            epoch_df.to_csv(self.history_file, index=False)\n","            self.file_exists = True  # Ora il file esiste\n","\n","        print(f\"Salvati i dati dell'epoca {epoch + 1} in {self.history_file}\")\n","\n","\n","\n","def generate_plot(path, epoch=0):\n","    # Percorso del file CSV contenente la storia dell'addestramento\n","    history_file = os.path.join(path, 'training_history.csv')\n","\n","    # Controlla se il file CSV esiste\n","    if not os.path.exists(history_file):\n","        print(f\"File {history_file} non trovato!\")\n","        return\n","\n","    # Carica i dati dal file CSV\n","    try:\n","        history_df = pd.read_csv(history_file)\n","    except Exception as e:\n","        print(f\"Errore durante la lettura del CSV: {e}\")\n","        return\n","\n","    # Verifica che le colonne necessarie esistano nel file CSV\n","    required_columns = ['epoch', 'training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss']\n","    if not all(col in history_df.columns for col in required_columns):\n","        print(\"Il file CSV non contiene tutte le colonne richieste.\")\n","        return\n","\n","    # Determina il numero massimo di epoche presenti nel file\n","    max_epoch_in_data = history_df['epoch'].max()\n","\n","    # Se l'epoch specificata è maggiore del numero di epoche disponibili, usa quella massima\n","    if epoch > 0:\n","        epoch = min(epoch, max_epoch_in_data)\n","        history_df = history_df[history_df['epoch'] <= epoch]\n","    else:\n","        epoch = max_epoch_in_data  # Usa tutte le epoche se epoch è 0\n","\n","    # Generazione del grafico di accuracy\n","    plt.plot(history_df['epoch'], history_df['training_accuracy'], label='Train')\n","    plt.plot(history_df['epoch'], history_df['validation_accuracy'], label='Validation')\n","    plt.title('Model accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(loc='upper left')\n","    accuracy_plot_path = os.path.join(path, 'accuracy_plot.png')\n","    plt.savefig(accuracy_plot_path)\n","    plt.show()  # Mostra il grafico di accuracy\n","    plt.close()  # Chiude il grafico corrente\n","    print(f\"Salvato grafico di accuracy in: {accuracy_plot_path}\")\n","\n","    # Generazione del grafico di loss\n","    plt.plot(history_df['epoch'], history_df['training_loss'], label='Train')\n","    plt.plot(history_df['epoch'], history_df['validation_loss'], label='Validation')\n","    plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(loc='upper left')\n","    loss_plot_path = os.path.join(path, 'loss_plot.png')\n","    plt.savefig(loss_plot_path)\n","    plt.show()  # Mostra il grafico di loss\n","    plt.close()  # Chiude il grafico corrente\n","    print(f\"Salvato grafico di loss in: {loss_plot_path}\")\n","\n","\n","\n","\n","def show_plots(path):\n","    # Percorso dei file di grafici salvati\n","    accuracy_plot_path = os.path.join(path, 'accuracy_plot.png')\n","    loss_plot_path = os.path.join(path, 'loss_plot.png')\n","\n","    # Controlla e mostra il grafico di accuracy\n","    if os.path.exists(accuracy_plot_path):\n","        accuracy_img = mpimg.imread(accuracy_plot_path)\n","        plt.imshow(accuracy_img)\n","        plt.axis('off')  # Rimuove gli assi\n","        plt.title('Model Accuracy')\n","        plt.show()  # Mostra il grafico di accuracy\n","    else:\n","        print(f\"Grafico di accuracy non trovato in: {accuracy_plot_path}\")\n","\n","    # Controlla e mostra il grafico di loss\n","    if os.path.exists(loss_plot_path):\n","        loss_img = mpimg.imread(loss_plot_path)\n","        plt.imshow(loss_img)\n","        plt.axis('off')  # Rimuove gli assi\n","        plt.title('Model Loss')\n","        plt.show()  # Mostra il grafico di loss\n","    else:\n","        print(f\"Grafico di loss non trovato in: {loss_plot_path}\")\n","\n","\n","\n","\n","def get_latest_epoch_number(folder_path):\n","    # Percorso del file CSV\n","    history_file = os.path.join(folder_path, 'training_history.csv')\n","\n","    # Controlla se il file CSV esiste\n","    if not os.path.exists(history_file):\n","        return None  # Se il file non esiste, restituisci None\n","\n","    # Legge il file CSV\n","    try:\n","        history_df = pd.read_csv(history_file)\n","\n","        # Controlla se ci sono dati nel file CSV\n","        if history_df.empty:\n","            return None  # Se il CSV è vuoto, restituisci None\n","\n","        # Ottiene l'ultima epoca dal campo 'epoch'\n","        last_epoch = history_df['epoch'].iloc[-1]  # Legge l'ultima riga del campo 'epoch'\n","\n","        return f\"{int(last_epoch):02d}\"  # Restituisce l'epoca formattata con due cifre\n","    except Exception as e:\n","        print(f\"Errore durante la lettura del CSV: {e}\")\n","        return None\n","\n","\n","\n","\n","def get_best_epoch_number(folder_path):\n","    # Espressione regolare per trovare i file con il pattern \"model_epoch_0N.keras\"\n","    pattern = r'model_epoch_(\\d+)\\.keras'\n","\n","    # Lista per tenere traccia dei numeri di epoca\n","    epoch_numbers = []\n","\n","    # Cerca i file nella cartella\n","    for filename in os.listdir(folder_path):\n","        # Cerca una corrispondenza con il pattern\n","        match = re.match(pattern, filename)\n","        if match:\n","            epoch_num = int(match.group(1))  # Estrae il numero dell'epoca\n","            epoch_numbers.append(epoch_num)\n","\n","    # Controlla se ci sono file corrispondenti\n","    if not epoch_numbers:\n","        return None  # Nessun file trovato con il pattern\n","\n","    # Restituisce il numero di epoca maggiore, formattato sempre con due cifre\n","    latest_epoch = max(epoch_numbers)\n","    return f\"{latest_epoch:02d}\"  # Formatta il numero con due cifre\n","\n","\n","\n","\n","def load_model(model, model_path):\n","    # Carica il modello dai pesi salvati\n","    best_model = get_best_epoch_number(model_path)\n","    model.load_weights(os.path.join(model_path, \"model_epoch_\" + best_model + \".keras\"))\n","\n","    # Stampare il sommario del modello\n","    print(model.summary())\n","\n","    # Percorsi dei grafici salvati\n","    accuracy_path = os.path.join(os.path.dirname(model_path), 'accuracy_plot.png')\n","    loss_path = os.path.join(os.path.dirname(model_path), 'loss_plot.png')\n","\n","    # Mostra i plot\n","    show_plots(model_path)\n","\n","    # Percorso del file CSV con la storia del training\n","    history_csv_path = os.path.join(model_path, 'training_history.csv')\n","\n","    # Controlla se il file CSV esiste\n","    if os.path.exists(history_csv_path):\n","        # Carica il file CSV\n","        training_history = pd.read_csv(history_csv_path)\n","        print(\"\\nContenuto di training_history.csv:\\n\")\n","        print(training_history)\n","    else:\n","        print(f\"File CSV 'training_history.csv' non trovato in {history_csv_path}\")\n","\n","\n","\n","\n","def train_model(model, path, train_gen, val_gen, epochs=50):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","    # EarlyStopping per fermare l'addestramento se il modello non migliora\n","    stop_early = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n","\n","    # ModelCheckpoint per salvare il miglior modello basato su val_accuracy\n","    checkpoint = ModelCheckpoint(\n","        filepath=os.path.join(path, \"model_epoch_{epoch:02d}.keras\"),\n","        monitor='val_accuracy',\n","        verbose=1,\n","        save_best_only=True,\n","        mode='max'\n","    )\n","\n","    # CSVLoggerCallback per monitorare come cambia l'accuracy e la loss ad ogni epoch\n","    csv_logger = CSVLoggerCallback(path)\n","\n","\n","    # Eseguo il training con il model e i dataset di training e validation\n","    history = model.fit(\n","        train_gen,\n","        validation_data=val_gen,\n","        epochs=epochs,\n","        callbacks=[csv_logger, checkpoint, stop_early]\n","    )\n","\n","    # Salvataggio dei grafici di accuratezza\n","    generate_plot(path)\n","\n","\n","# Carica il modello dal checkpoint (l'ultimo salvato)\n","def continue_model(model, model_path, train_gen, val_gen, epochs=50, from_best=0):\n","  load_model(model, model_path)\n","\n","  # EarlyStopping per fermare l'addestramento se il modello non migliora\n","  stop_early = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n","\n","  # ModelCheckpoint per salvare il miglior modello basato su val_accuracy\n","  checkpoint = ModelCheckpoint(\n","      filepath=os.path.join(model_path, \"model_epoch_{epoch:02d}.keras\"),\n","      monitor='val_accuracy',\n","      verbose=1,\n","      save_best_only=True,\n","      mode='max'\n","  )\n","\n","  # CSVLoggerCallback per monitorare come cambia l'accuracy e la loss ad ogni epoch\n","  csv_logger = CSVLoggerCallback(model_path)\n","\n","  if (from_best): best_model = get_best_epoch_number(model_path)\n","  else: best_model = get_latest_epoch_number(model_path)\n","  start_epoch = int(best_model)\n","\n","  # Continua il training da dove è stato interrotto\n","  history = model.fit(\n","      train_gen,\n","      validation_data=val_gen,\n","      initial_epoch=start_epoch,  # Imposta l'epoca iniziale a 26 (ultimo checkpoint salvato)\n","      epochs=epochs,         # Continua fino all'epoca 50 o più, se desiderato\n","      callbacks=[csv_logger, checkpoint, stop_early]  # Mantieni le callback originali\n","  )\n","\n","  # Salvataggio dei grafici di accuratezza\n","  generate_plot(model_path)\n","\n","\n","print(\"ml_utils.py caricato correttamente!\")"]}]}